{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LangChain**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Framework para desarrollar apps basadas en LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install --upgrade --quiet  langchain\n",
    "! pip install langchain-community\n",
    "! pip install langchainhub\n",
    "! pip install langchain-openai\n",
    "! pip install chromadb bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : LLM**\n",
    "\n",
    "- OpenAI: Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicia el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a recipe using {ingredient}.\")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"ingredient\": \"tomato\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe: Tomato Basil Bruschetta\n",
      "\n",
      "Ingredients:\n",
      "- 4 ripe tomatoes, diced\n",
      "- 1/4 cup fresh basil leaves, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 2 tablespoons extra virgin olive oil\n",
      "- 1 tablespoon balsamic vinegar\n",
      "- Salt and pepper to taste\n",
      "- Baguette or crusty bread, sliced\n",
      "- Optional: Mozzarella cheese, sliced\n",
      "\n",
      "Instructions:\n",
      "1. Preheat the oven to 375°F (190°C). Place the sliced baguette or bread on a baking sheet and toast in the oven until lightly golden and crispy, about 8-10 minutes. Remove from the oven and set aside.\n",
      "\n",
      "2. In a medium bowl, combine the diced tomatoes, chopped basil, minced garlic, olive oil, and balsamic vinegar. Mix well to combine all the flavors. Season with salt and pepper to taste.\n",
      "\n",
      "3. If desired, spread a thin layer of sliced mozzarella cheese on each toasted bread slice. Return the bread to the oven for a few minutes until the cheese melts and starts to bubble.\n",
      "\n",
      "4. Spoon the tomato basil mixture generously over each bread slice. If you skipped the cheese, you can also drizzle a little extra olive oil over the top.\n",
      "\n",
      "5. Serve the bruschetta immediately as an appetizer or snack. It can also be enjoyed as a light lunch or dinner alongside a fresh salad.\n",
      "\n",
      "Note: You can customize this recipe by adding other ingredients such as diced red onions, chopped olives, or a sprinkle of grated Parmesan cheese. Feel free to experiment and make it your own!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenAI: Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.019610895550667983,\n",
       " -0.03274273617843824,\n",
       " -0.011946397332724516,\n",
       " 0.040325479172545385,\n",
       " -0.01069963855112415]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the docs or text (in this case it will be the tomato recipe)\n",
    "text = response \n",
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.019610895550667983,\n",
       " -0.03274273617843824,\n",
       " -0.011946397332724516,\n",
       " 0.040325479172545385,\n",
       " -0.01069963855112415]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the query\n",
    "query = \"How many ingredients will I need for this recipe?\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : Chains**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q&A : Indexing**\n",
    "\n",
    "- Cargar texto (documentos, base de conocimiento)\n",
    "- Trocear el texto para poder hacer llamadas a la API\n",
    "- Almacenar el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"documents/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "diana.bisbe@gmail.com\n",
      "www.linkedin.com/in/\n",
      "dianadiazbisbe  (LinkedIn)\n",
      "Top Skills\n",
      "Semantic Kernel\n",
      ".NET Framework\n",
      "Back-End Development\n",
      "Certifications\n",
      "Power BI Data Modeling with DAX\n",
      "Global AI Bootcamp Participant\n",
      "Intro to GitHub Copilot Course\n",
      "Intro to Generative AI Course\n",
      "BI Dashboards with Power BI\n",
      "CourseDiana Diaz Bisbe\n",
      "Cloud Solutions Developer @ ENCAMINA | Computer Science\n",
      "Madrid, Community of Madrid, Spain\n",
      "Summary\n",
      "Diana Diaz Bisbe is a software engineer dedicated to the world of\n",
      "artificial intelligence. \n",
      "Her passion for technology and her ability to solve complex technical\n",
      "problems are evident in her work, where she primarily uses Python\n",
      "and C# to develop impactful applications. Diana holds a degree in\n",
      "Computer Science from the University of Central Florida. She is an\n",
      "avid advocate for lifelong learning and stands out as a speaker in the\n",
      "artificial intelligence community. She has held roles as a developer in\n",
      "image processing and recognition projects, as well as in the creation\n",
      "of solutions and applications using generative artificial intelligence.\n",
      "She is also a movie buff and a bookworm, who loves to explore the\n",
      "great outdoors and discuss the nuances of films and literature. She\n",
      "values curiosity, collaboration, and creativity.\n",
      "Experience\n",
      "ENCAMINA\n",
      "Cloud Solutions Developer\n",
      "July 2023 - Present  (8 months)\n",
      "Madrid, Community of Madrid, Spain\n",
      "Isemaren\n",
      "Artificial Intelligence Tech\n",
      "June 2023 - July 2023  (2 months)\n",
      "Madrid, Community of Madrid, Spain\n",
      "Full Sail University\n",
      "Staff\n",
      "August 2021 - August 2022  (1 year 1 month)\n",
      "Winter Park, Florida, United States\n",
      "University of Central Florida\n",
      "  Page 1 of 2\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk and embed the documents\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "text = '''You are an assistant for question-answering tasks. Use the following pieces of\n",
    "        retrieved context to answer the question. If you don't know the answer, just say \n",
    "        that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "        Question: {question} \n",
    "\n",
    "        Context: {context} \n",
    "\n",
    "        Answer:\n",
    "        '''\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(text)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (format_docs(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'ingredient'}.  Expected: ['ingredient'] Received: ['context', 'question']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Invoke the chain to get the response\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m¿Qué me puedes decir acerca del contexto?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\runnables\\base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\prompts\\base.py:112\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    111\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\runnables\\base.py:1246\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1243\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1244\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1245\u001b[0m         Output,\n\u001b[1;32m-> 1246\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1254\u001b[0m     )\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\runnables\\config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\prompts\\base.py:97\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m     95\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inner_input\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_input)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'ingredient'}.  Expected: ['ingredient'] Received: ['context', 'question']\""
     ]
    }
   ],
   "source": [
    "# Invoke the chain to get the response\n",
    "chain.invoke(\"¿Qué me puedes decir acerca del contexto?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LangChain Components: Chains**\n",
    "\n",
    "- secuencias de llamadas, ya sea a un LLM, una herramienta o un paso de preprocesamiento de datos\n",
    "- LCEL facilita la creación de cadenas complejas a partir de componentes básicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt + model + output parser Chain\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a recipe using the ingredient {ingredient}\")\n",
    "model = ChatOpenAI(model_name= \"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "choco_recipe = chain.invoke({\"ingredient\": \"chocolate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe: Chocolate Banana Bread\n",
      "\n",
      "Ingredients:\n",
      "- 1 ½ cups all-purpose flour\n",
      "- 1 teaspoon baking powder\n",
      "- ½ teaspoon baking soda\n",
      "- ½ teaspoon salt\n",
      "- ¼ cup unsweetened cocoa powder\n",
      "- ½ cup granulated sugar\n",
      "- ½ cup unsalted butter, softened\n",
      "- 2 ripe bananas, mashed\n",
      "- 2 large eggs\n",
      "- 1 teaspoon vanilla extract\n",
      "- ½ cup milk\n",
      "- 1 cup chocolate chips\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 350°F (175°C). Grease and flour a loaf pan.\n",
      "\n",
      "2. In a medium-sized bowl, whisk together the flour, baking powder, baking soda, salt, and cocoa powder until well combined. Set aside.\n",
      "\n",
      "3. In a large mixing bowl, cream together the softened butter and granulated sugar until light and fluffy.\n",
      "\n",
      "4. Add the mashed bananas, eggs, and vanilla extract to the butter mixture. Beat until well incorporated.\n",
      "\n",
      "5. Gradually add the dry ingredients to the wet mixture, alternating with the milk. Begin and end with the dry ingredients. Mix until just combined, being careful not to overmix.\n",
      "\n",
      "6. Gently fold in the chocolate chips into the batter.\n",
      "\n",
      "7. Pour the batter into the prepared loaf pan, spreading it evenly.\n",
      "\n",
      "8. Bake in the preheated oven for about 50-60 minutes, or until a toothpick inserted into the center comes out clean.\n",
      "\n",
      "9. Once baked, remove the banana bread from the oven and allow it to cool in the pan for about 10 minutes. Then, transfer it to a wire rack to cool completely.\n",
      "\n",
      "10. Slice and serve the chocolate banana bread on its own or with a dollop of whipped cream or a scoop of vanilla ice cream. Enjoy!\n",
      "\n",
      "Note: You can customize this recipe by adding nuts or dried fruits to the batter for added flavor and texture.\n"
     ]
    }
   ],
   "source": [
    "print (choco_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Write a recipe using the ingredient chocolate')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prompt component takes the user input, \n",
    "# which is then used to construct a PromptValue \n",
    "# after using the topic to construct the prompt.\n",
    "\n",
    "prompt_value = prompt.invoke({\"ingredient\": \"chocolate\"})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a recipe using the ingredient chocolate'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Recipe: Decadent Chocolate Brownies\\n\\nIngredients:\\n- 1 cup unsalted butter\\n- 2 cups granulated sugar\\n- 4 large eggs\\n- 1 teaspoon vanilla extract\\n- 1 cup all-purpose flour\\n- 1/2 cup cocoa powder\\n- 1/2 teaspoon baking powder\\n- 1/4 teaspoon salt\\n- 1 cup chocolate chips (semi-sweet or dark)\\n- Optional: 1/2 cup chopped nuts (walnuts or pecans)\\n\\nInstructions:\\n\\n1. Preheat your oven to 350°F (175°C). Grease and flour a 9x13-inch baking dish.\\n\\n2. In a microwave-safe bowl, melt the butter in the microwave or on the stovetop until fully melted. Allow it to cool slightly.\\n\\n3. In a large mixing bowl, combine the melted butter and granulated sugar. Stir until well combined.\\n\\n4. Add the eggs one at a time, mixing well after each addition. Stir in the vanilla extract.\\n\\n5. In a separate bowl, whisk together the flour, cocoa powder, baking powder, and salt.\\n\\n6. Gradually add the dry ingredients to the wet ingredients, mixing until just combined. Do not overmix.\\n\\n7. Fold in the chocolate chips and chopped nuts (if desired). Reserve a small handful of chocolate chips to sprinkle on top.\\n\\n8. Pour the brownie batter into the prepared baking dish and spread it evenly.\\n\\n9. Sprinkle the reserved chocolate chips on top of the batter.\\n\\n10. Bake in the preheated oven for about 25-30 minutes, or until a toothpick inserted in the center comes out with a few moist crumbs.\\n\\n11. Remove from the oven and allow the brownies to cool completely in the baking dish before cutting into squares.\\n\\n12. Serve and enjoy these rich and fudgy chocolate brownies on their own or with a scoop of vanilla ice cream!\\n\\nNote: You can also add other mix-ins to these brownies, such as caramel, marshmallows, or additional flavors like mint or orange extract, to personalize them to your taste.')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# component takes the generated prompt, \n",
    "# and passes into the OpenAI LLM model for evaluation. \n",
    "# The generated output from the model is a ChatMessage object.\n",
    "\n",
    "message = model.invoke(prompt_value)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe: Decadent Chocolate Brownies\\n\\nIngredients:\\n- 1 cup unsalted butter\\n- 2 cups granulated sugar\\n- 4 large eggs\\n- 1 teaspoon vanilla extract\\n- 1 cup all-purpose flour\\n- 1/2 cup cocoa powder\\n- 1/2 teaspoon baking powder\\n- 1/4 teaspoon salt\\n- 1 cup chocolate chips (semi-sweet or dark)\\n- Optional: 1/2 cup chopped nuts (walnuts or pecans)\\n\\nInstructions:\\n\\n1. Preheat your oven to 350°F (175°C). Grease and flour a 9x13-inch baking dish.\\n\\n2. In a microwave-safe bowl, melt the butter in the microwave or on the stovetop until fully melted. Allow it to cool slightly.\\n\\n3. In a large mixing bowl, combine the melted butter and granulated sugar. Stir until well combined.\\n\\n4. Add the eggs one at a time, mixing well after each addition. Stir in the vanilla extract.\\n\\n5. In a separate bowl, whisk together the flour, cocoa powder, baking powder, and salt.\\n\\n6. Gradually add the dry ingredients to the wet ingredients, mixing until just combined. Do not overmix.\\n\\n7. Fold in the chocolate chips and chopped nuts (if desired). Reserve a small handful of chocolate chips to sprinkle on top.\\n\\n8. Pour the brownie batter into the prepared baking dish and spread it evenly.\\n\\n9. Sprinkle the reserved chocolate chips on top of the batter.\\n\\n10. Bake in the preheated oven for about 25-30 minutes, or until a toothpick inserted in the center comes out with a few moist crumbs.\\n\\n11. Remove from the oven and allow the brownies to cool completely in the baking dish before cutting into squares.\\n\\n12. Serve and enjoy these rich and fudgy chocolate brownies on their own or with a scoop of vanilla ice cream!\\n\\nNote: You can also add other mix-ins to these brownies, such as caramel, marshmallows, or additional flavors like mint or orange extract, to personalize them to your taste.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRecipe: Chocolate Chip Cookies\\n\\nIngredients:\\n- 1 cup all-purpose flour\\n- 1/2 tsp baking soda\\n- 1/2 tsp salt\\n- 1/2 cup unsalted butter, softened\\n- 1/2 cup granulated sugar\\n- 1/4 cup brown sugar\\n- 1 egg\\n- 1 tsp vanilla extract\\n- 1 cup chocolate chips\\n\\nInstructions:\\n\\n1. Preheat your oven to 375°F (190°C) and line a baking sheet with parchment paper.\\n2. In a medium bowl, whisk together the flour, baking soda, and salt. Set aside.\\n3. In a separate large bowl, cream together the softened butter, granulated sugar, and brown sugar until light and fluffy.\\n4. Add in the egg and vanilla extract, and mix until well combined.\\n5. Gradually add in the dry ingredients to the wet mixture, mixing until a dough forms.\\n6. Fold in the chocolate chips until evenly distributed throughout the dough.\\n7. Using a spoon or cookie scoop, drop the dough onto the prepared baking sheet, leaving about 2 inches of space between each cookie.\\n8. Bake for 10-12 minutes, or until the edges are golden brown.\\n9. Let'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the output_parser component takes in a ChatMessage,\n",
    "# and transforms this into a Python string,\n",
    "# which is returned from the invoke method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tools**\n",
    "\n",
    "- interfaces que un Agent puede usar para interactuar con el mundo.\n",
    "    - Nombre\n",
    "    - Descripción\n",
    "    - Esquema JSON de cuáles son los datos de entrada\n",
    "    - Función a llamar\n",
    "    - Si el resultado debe ser devuelto directamente al usuario\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name, description, and JSON schema can be used the prompt the LLM so it knows \n",
    "# how to specify what action to take, \n",
    "# and then the function to call is equivalent to taking that action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=EQ3DakqVrvo&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=OuPRkFQAm9c&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=R4peoHkXsJg&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=we_wLw-1fwg&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=NgDGlcxYrhQ&pp=ygUKam9obiBncmVlbg%3D%3D']\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Built in tools\n",
    "from langchain.tools import YouTubeSearchTool\n",
    "\n",
    "tool = YouTubeSearchTool()\n",
    "\n",
    "tool.run(\"john green, 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Custom tools\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "# This @tool decorator is the simplest way to define a custom tool.\n",
    "# The decorator uses the function name as the tool name by default\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agents**\n",
    "\n",
    "- es la cadena responsable de decidir qué paso dar a continuación. Por lo general, esto funciona con un modelo de lenguaje, un mensaje y un output parser.\n",
    "- el agent executor es el runtime de un agente. Esto es lo que realmente llama al agente, ejecuta las acciones que elige, devuelve los resultados de la acción al agente y repite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom Agent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_palindrome(word):\n",
    "    return word == word[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# Define a custom tool\n",
    "@tool\n",
    "def is_palindrome_tool(word: str) -> bool:\n",
    "    \"\"\"Checks if a word is palindrome\"\"\"\n",
    "    return is_palindrome(word)\n",
    "\n",
    "\n",
    "is_palindrome_tool.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [is_palindrome_tool, get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the llm know what tools it can use\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2185729952.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[62], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    list(agent_executor.stream({\"input\": \"+´{¿Cuántas letras hay en la palabra \"chocolate\"}\"}))\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"{¿Cuántas letras hay en la palabra chocolate}\"}))"
   ]
  }
 ],
 "metadata": {},
   "outputs": []
}
