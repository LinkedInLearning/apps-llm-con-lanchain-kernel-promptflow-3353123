{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LangChain**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Framework para desarrollar apps basadas en LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install --upgrade --quiet  langchain\n",
    "! pip install langchain-community\n",
    "! pip install langchainhub\n",
    "! pip install langchain-openai\n",
    "! pip install chromadb bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : LLM**\n",
    "\n",
    "- OpenAI: Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicia el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a recipe using {ingredient}.\")\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"ingredient\": \"potato\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenAI: Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAIEmbeddings and size 3\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.019610895550667983,\n",
       " -0.03274273617843824,\n",
       " -0.011946397332724516,\n",
       " 0.040325479172545385,\n",
       " -0.01069963855112415]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the text\n",
    "text = response \n",
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result[0][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.019610895550667983,\n",
       " -0.03274273617843824,\n",
       " -0.011946397332724516,\n",
       " 0.040325479172545385,\n",
       " -0.01069963855112415]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the query\n",
    "query = \"How many ingredients will I need for this recipe?\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : Chains**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q&A : Indexing**\n",
    "\n",
    "- Cargar texto (documentos, base de conocimiento)\n",
    "- Trocear el texto para poder hacer llamadas a la API\n",
    "- Almacenar el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"documents/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "diana.bisbe@gmail.com\n",
      "www.linkedin.com/in/\n",
      "dianadiazbisbe  (LinkedIn)\n",
      "Top Skills\n",
      "Semantic Kernel\n",
      ".NET Framework\n",
      "Back-End Development\n",
      "Certifications\n",
      "Power BI Data Modeling with DAX\n",
      "Global AI Bootcamp Participant\n",
      "Intro to GitHub Copilot Course\n",
      "Intro to Generative AI Course\n",
      "BI Dashboards with Power BI\n",
      "CourseDiana Diaz Bisbe\n",
      "Cloud Solutions Developer @ ENCAMINA | Computer Science\n",
      "Madrid, Community of Madrid, Spain\n",
      "Summary\n",
      "Diana Diaz Bisbe is a software engineer dedicated to the world of\n",
      "artificial intelligence. \n",
      "Her passion for technology and her ability to solve complex technical\n",
      "problems are evident in her work, where she primarily uses Python\n",
      "and C# to develop impactful applications. Diana holds a degree in\n",
      "Computer Science from the University of Central Florida. She is an\n",
      "avid advocate for lifelong learning and stands out as a speaker in the\n",
      "artificial intelligence community. She has held roles as a developer in\n",
      "image processing and recognition projects, as well as in the creation\n",
      "of solutions and applications using generative artificial intelligence.\n",
      "She is also a movie buff and a bookworm, who loves to explore the\n",
      "great outdoors and discuss the nuances of films and literature. She\n",
      "values curiosity, collaboration, and creativity.\n",
      "Experience\n",
      "ENCAMINA\n",
      "Cloud Solutions Developer\n",
      "July 2023 - Present  (8 months)\n",
      "Madrid, Community of Madrid, Spain\n",
      "Isemaren\n",
      "Artificial Intelligence Tech\n",
      "June 2023 - July 2023  (2 months)\n",
      "Madrid, Community of Madrid, Spain\n",
      "Full Sail University\n",
      "Staff\n",
      "August 2021 - August 2022  (1 year 1 month)\n",
      "Winter Park, Florida, United States\n",
      "University of Central Florida\n",
      "  Page 1 of 2\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk and embed the documents\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "prompt_text = '''You are an assistant for question-answering tasks. Use the following pieces of\n",
    "        retrieved context to answer the question. If you don't know the answer, just say \n",
    "        that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "        Question: {question} \n",
    "\n",
    "        Context: {context} \n",
    "\n",
    "        Answer:\n",
    "        '''\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (format_docs(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qué me puedes decir acerca del contexto?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LangChain Components: Chains**\n",
    "\n",
    "- secuencias de llamadas, ya sea a un LLM, una herramienta o un paso de preprocesamiento de datos\n",
    "- LCEL facilita la creación de cadenas complejas a partir de componentes básicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt + model + output parser Chain\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a recipe using the ingredient {ingredient}\")\n",
    "model = ChatOpenAI(model_name= \"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "choco_recipe = chain.invoke({\"ingredient\": \"chocolate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple Chocolate Brownies\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup unsalted butter\n",
      "- 2 cups granulated sugar\n",
      "- 4 large eggs\n",
      "- 1 teaspoon vanilla extract\n",
      "- 1 cup all-purpose flour\n",
      "- 1/2 cup cocoa powder\n",
      "- 1/4 teaspoon salt\n",
      "- 1 cup dark chocolate chips\n",
      "- 1 cup milk chocolate chips\n",
      "- 1 cup white chocolate chips\n",
      "\n",
      "Instructions:\n",
      "1. Preheat the oven to 350°F (175°C). Grease a 9x13 inch baking dish and set aside.\n",
      "2. In a microwave-safe bowl, melt the butter. Let it cool slightly.\n",
      "3. In a separate large mixing bowl, whisk together the sugar and melted butter.\n",
      "4. Add the eggs one at a time, whisking well after each addition. Stir in the vanilla extract.\n",
      "5. In a medium bowl, sift together the flour, cocoa powder, and salt. Gradually add this dry mixture to the wet ingredients, stirring until just combined.\n",
      "6. Fold in the dark chocolate chips, milk chocolate chips, and white chocolate chips, reserving a small handful of each variety for topping.\n",
      "7. Pour the batter into the prepared baking dish and spread it evenly. Sprinkle the reserved chocolate chips on top.\n",
      "8. Bake for 25-30 minutes or until a toothpick inserted in the center comes out with a few moist crumbs. Be careful not to overbake as brownies continue to cook as they cool.\n",
      "9. Remove from the oven and let the brownies cool completely in the baking dish before cutting into squares.\n",
      "10. Serve and enjoy these decadent triple chocolate brownies!\n",
      "\n",
      "Optional: You can add chopped nuts or swirl in some peanut butter before baking for extra flavor and texture.\n"
     ]
    }
   ],
   "source": [
    "print (choco_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Write a recipe using the ingredient chocolate')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prompt component takes the user input, \n",
    "# which is then used to construct a PromptValue \n",
    "# after using the topic to construct the prompt.\n",
    "\n",
    "prompt_value = prompt.invoke({\"ingredient\": \"chocolate\"})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a recipe using the ingredient chocolate'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Recipe: Decadent Chocolate Brownies\\n\\nIngredients:\\n- 1 cup unsalted butter\\n- 2 cups granulated sugar\\n- 4 large eggs\\n- 1 teaspoon vanilla extract\\n- 1 cup all-purpose flour\\n- 1/2 cup cocoa powder\\n- 1/4 teaspoon salt\\n- 1 cup chocolate chips (semi-sweet or dark)\\n\\nInstructions:\\n1. Preheat your oven to 350°F (175°C). Grease a 9x13-inch baking dish and set aside.\\n\\n2. In a microwave-safe bowl, melt the butter. Allow it to cool slightly.\\n\\n3. In a large mixing bowl, combine the melted butter and granulated sugar. Mix well until fully incorporated.\\n\\n4. Add the eggs, one at a time, mixing well after each addition. Stir in the vanilla extract.\\n\\n5. In a separate bowl, sift together the all-purpose flour, cocoa powder, and salt. Gradually add the dry ingredients to the wet mixture, stirring until just combined. Do not overmix.\\n\\n6. Gently fold in the chocolate chips, reserving a handful for topping.\\n\\n7. Pour the batter into the prepared baking dish, spreading it evenly. Sprinkle the reserved chocolate chips on top.\\n\\n8. Bake in the preheated oven for approximately 30-35 minutes, or until a toothpick inserted into the center comes out with a few moist crumbs. Be careful not to overbake, as brownies continue to cook as they cool.\\n\\n9. Remove the brownies from the oven and allow them to cool completely in the baking dish before cutting into squares.\\n\\n10. Serve these decadent chocolate brownies as is or with a scoop of vanilla ice cream, and enjoy!\\n\\nNote: You can customize this recipe by adding chopped nuts, caramel, or any other desired mix-ins to the batter.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# component takes the generated prompt, \n",
    "# and passes into the OpenAI LLM model for evaluation. \n",
    "# The generated output from the model is a ChatMessage object.\n",
    "\n",
    "message = model.invoke(prompt_value)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe: Decadent Chocolate Brownies\\n\\nIngredients:\\n- 1 cup unsalted butter\\n- 2 cups granulated sugar\\n- 4 large eggs\\n- 1 teaspoon vanilla extract\\n- 1 cup all-purpose flour\\n- 1/2 cup cocoa powder\\n- 1/4 teaspoon salt\\n- 1 cup chocolate chips (semi-sweet or dark)\\n\\nInstructions:\\n1. Preheat your oven to 350°F (175°C). Grease a 9x13-inch baking dish and set aside.\\n\\n2. In a microwave-safe bowl, melt the butter. Allow it to cool slightly.\\n\\n3. In a large mixing bowl, combine the melted butter and granulated sugar. Mix well until fully incorporated.\\n\\n4. Add the eggs, one at a time, mixing well after each addition. Stir in the vanilla extract.\\n\\n5. In a separate bowl, sift together the all-purpose flour, cocoa powder, and salt. Gradually add the dry ingredients to the wet mixture, stirring until just combined. Do not overmix.\\n\\n6. Gently fold in the chocolate chips, reserving a handful for topping.\\n\\n7. Pour the batter into the prepared baking dish, spreading it evenly. Sprinkle the reserved chocolate chips on top.\\n\\n8. Bake in the preheated oven for approximately 30-35 minutes, or until a toothpick inserted into the center comes out with a few moist crumbs. Be careful not to overbake, as brownies continue to cook as they cool.\\n\\n9. Remove the brownies from the oven and allow them to cool completely in the baking dish before cutting into squares.\\n\\n10. Serve these decadent chocolate brownies as is or with a scoop of vanilla ice cream, and enjoy!\\n\\nNote: You can customize this recipe by adding chopped nuts, caramel, or any other desired mix-ins to the batter.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRecipe for Chocolate Fudge Brownies:\\n\\nIngredients:\\n- 1 cup all-purpose flour\\n- 1/2 cup unsalted butter\\n- 1 cup granulated sugar\\n- 1 teaspoon vanilla extract\\n- 2 large eggs\\n- 1/2 teaspoon baking powder\\n- 1/2 teaspoon salt\\n- 1/2 cup chocolate chips\\n- 1/2 cup chopped walnuts (optional)\\n- 1/2 cup unsweetened cocoa powder\\n- 1/4 cup milk\\n- 1/4 cup vegetable oil\\n\\nInstructions:\\n\\n1. Preheat your oven to 350°F (180°C) and line a 9x9 inch baking pan with parchment paper.\\n\\n2. In a medium-sized bowl, mix together the flour, baking powder, and salt. Set aside.\\n\\n3. In a large saucepan, melt the butter over medium heat. Once melted, remove from heat and stir in the sugar, vanilla extract, and cocoa powder.\\n\\n4. Add in the eggs, one at a time, mixing well after each addition.\\n\\n5. Gradually stir in the flour mixture until well combined.\\n\\n6. In a small saucepan, heat the milk and vegetable oil until just warm.\\n\\n7. Slowly'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the output_parser component takes in a ChatMessage,\n",
    "# and transforms this into a Python string,\n",
    "# which is returned from the invoke method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tools**\n",
    "\n",
    "- interfaces que un Agent puede usar para interactuar con el mundo.\n",
    "    - Nombre\n",
    "    - Descripción\n",
    "    - Esquema JSON de cuáles son los datos de entrada\n",
    "    - Función a llamar\n",
    "    - Si el resultado debe ser devuelto directamente al usuario\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name, description, and JSON schema can be used the prompt the LLM so it knows \n",
    "# how to specify what action to take, \n",
    "# and then the function to call is equivalent to taking that action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=IsEmm3i2BH0&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=R4peoHkXsJg&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=EQ3DakqVrvo&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=we_wLw-1fwg&pp=ygUKam9obiBncmVlbg%3D%3D', 'https://www.youtube.com/watch?v=NgDGlcxYrhQ&pp=ygUKam9obiBncmVlbg%3D%3D']\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Built in tools\n",
    "from langchain.tools import YouTubeSearchTool\n",
    "\n",
    "tool = YouTubeSearchTool()\n",
    "\n",
    "tool.run(\"john green, 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Custom tools\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "# This @tool decorator is the simplest way to define a custom tool.\n",
    "# The decorator uses the function name as the tool name by default\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agents**\n",
    "\n",
    "- es la cadena responsable de decidir qué paso dar a continuación. Por lo general, esto funciona con un modelo de lenguaje, un mensaje y un output parser.\n",
    "- el agent executor es el runtime de un agente. Esto es lo que realmente llama al agente, ejecuta las acciones que elige, devuelve los resultados de la acción al agente y repite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom Agent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_palindrome(word):\n",
    "    return word == word[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# Define a custom tool\n",
    "@tool\n",
    "def is_palindrome_tool(word: str) -> bool:\n",
    "    \"\"\"Checks if a word is palindrome\"\"\"\n",
    "    return is_palindrome(word)\n",
    "\n",
    "\n",
    "is_palindrome_tool.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [is_palindrome_tool, get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the llm know what tools it can use\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"eudca\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [OpenAIToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_darbvI9EoDJEkHvV5hVScShY', 'function': {'arguments': '{\\n  \"word\": \"eudca\"\\n}', 'name': 'get_word_length'}, 'type': 'function'}]})], tool_call_id='call_darbvI9EoDJEkHvV5hVScShY')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_darbvI9EoDJEkHvV5hVScShY', 'function': {'arguments': '{\\n  \"word\": \"eudca\"\\n}', 'name': 'get_word_length'}, 'type': 'function'}]})]},\n",
       " {'steps': [AgentStep(action=OpenAIToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_darbvI9EoDJEkHvV5hVScShY', 'function': {'arguments': '{\\n  \"word\": \"eudca\"\\n}', 'name': 'get_word_length'}, 'type': 'function'}]})], tool_call_id='call_darbvI9EoDJEkHvV5hVScShY'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', name='get_word_length')]},\n",
       " {'output': 'There are 5 letters in the word \"eudca\".',\n",
       "  'messages': [AIMessage(content='There are 5 letters in the word \"eudca\".')]}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"+´{¿Cuántas letras hay en la palabra \"chocolate\"}\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
