{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LangChain**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Framework para desarrollar apps basadas en LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install --upgrade --quiet  langchain\n",
    "! pip install langchain-community\n",
    "! pip install langchainhub\n",
    "! pip install langchain-openai\n",
    "! pip install chromadb bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : LLM**\n",
    "\n",
    "- OpenAI: Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicia el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a recipe for the {ingredient}\")\n",
    "\n",
    "chain = prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenAI: Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAIEmbeddings and size 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : Chains**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q&A : Indexing**\n",
    "\n",
    "- Cargar texto (documentos, base de conocimiento)\n",
    "- Trocear el texto para poder hacer llamadas a la API\n",
    "- Almacenar el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"documents/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "diana.bisbe@gmail.com\n",
      "www.linkedin.com/in/\n",
      "dianadiazbisbe  (LinkedIn)\n",
      "Top Skills\n",
      "Semantic Kernel\n",
      ".NET Framework\n",
      "Back-End Development\n",
      "Certifications\n",
      "Power BI Data Modeling with DAX\n",
      "Global AI Bootcamp Participant\n",
      "Intro to GitHub Copilot Course\n",
      "Intro to Generative AI Course\n",
      "BI Dashboards with Power BI\n",
      "CourseDiana Diaz Bisbe\n",
      "Cloud Solutions Developer @ ENCAMINA | Computer Science\n",
      "Madrid, Community of Madrid, Spain\n",
      "Summary\n",
      "Diana Diaz Bisbe is a software engineer dedicated to the world of\n",
      "artificial intelligence. \n",
      "Her passion for technology and her ability to solve complex technical\n",
      "problems are evident in her work, where she primarily uses Python\n",
      "and C# to develop impactful applications. Diana holds a degree in\n",
      "Computer Science from the University of Central Florida. She is an\n",
      "avid advocate for lifelong learning and stands out as a speaker in the\n",
      "artificial intelligence community. She has held roles as a developer in\n",
      "image processing and recognition projects, as well as in the creation\n",
      "of solutions and applications using generative artificial intelligence.\n",
      "She is also a movie buff and a bookworm, who loves to explore the\n",
      "great outdoors and discuss the nuances of films and literature. She\n",
      "values curiosity, collaboration, and creativity.\n",
      "Experience\n",
      "ENCAMINA\n",
      "Cloud Solutions Developer\n",
      "July 2023 - Present  (8 months)\n",
      "Madrid, Community of Madrid, Spain\n",
      "Isemaren\n",
      "Artificial Intelligence Tech\n",
      "June 2023 - July 2023  (2 months)\n",
      "Madrid, Community of Madrid, Spain\n",
      "Full Sail University\n",
      "Staff\n",
      "August 2021 - August 2022  (1 year 1 month)\n",
      "Winter Park, Florida, United States\n",
      "University of Central Florida\n",
      "  Page 1 of 2\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk and embed the documents\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "prompt_text = '''You are an assistant for question-answering tasks. Use the following pieces of\n",
    "        retrieved context to answer the question. If you don't know the answer, just say \n",
    "        that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "        Question: {question} \n",
    "\n",
    "        Context: {context} \n",
    "\n",
    "        Answer:\n",
    "        '''\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (format_docs(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Qué me puedes decir acerca del contexto?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
