{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LangChain**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Framework para desarrollar apps basadas en LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install --upgrade --quiet  langchain\n",
    "! pip install langchain-community\n",
    "! pip install langchainhub\n",
    "! pip install langchain-openai\n",
    "! pip install chromadb bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "key = \"Hello\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : LLM**\n",
    "\n",
    "- OpenAI: Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicia el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a recipe using {ingredient}.\")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"ingredient\": \"tomato\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe: Tomato Basil Bruschetta\n",
      "\n",
      "Ingredients:\n",
      "- 4 ripe tomatoes, diced\n",
      "- 1/4 cup fresh basil leaves, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 2 tablespoons extra virgin olive oil\n",
      "- 1 tablespoon balsamic vinegar\n",
      "- Salt and pepper, to taste\n",
      "- Baguette or crusty bread, sliced\n",
      "- Optional toppings: mozzarella cheese, prosciutto, or avocado\n",
      "\n",
      "Instructions:\n",
      "1. In a medium bowl, combine the diced tomatoes, chopped basil, minced garlic, olive oil, and balsamic vinegar. Mix well to combine.\n",
      "2. Season the tomato mixture with salt and pepper according to your taste. Set aside and let it marinate for at least 15 minutes to allow the flavors to meld together.\n",
      "3. Preheat your oven to 375°F (190°C). Arrange the sliced baguette or crusty bread on a baking sheet.\n",
      "4. Brush each slice of bread with a little olive oil and place them in the preheated oven. Bake for about 8-10 minutes or until the bread turns golden and crispy.\n",
      "5. Remove the bread from the oven and let it cool slightly. If desired, you can rub each slice with a garlic clove for extra flavor.\n",
      "6. Spoon the tomato basil mixture generously over each slice of bread. If desired, you can also add additional toppings like mozzarella cheese, prosciutto, or avocado.\n",
      "7. Serve the tomato basil bruschetta immediately as an appetizer or a light snack. Enjoy!\n",
      "\n",
      "Note: You can customize this recipe by adding other ingredients such as diced onions, chopped olives, or even a sprinkle of Parmesan cheese. Feel free to experiment and make it your own!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenAI: Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.02423724047655008,\n",
       " -0.028520545865452353,\n",
       " -0.01385283698896719,\n",
       " 0.03834080813674366,\n",
       " -0.017206350869055486]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the docs or text (in this case it will be the tomato recipe)\n",
    "text = response \n",
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.02423724047655008,\n",
       " -0.028520545865452353,\n",
       " -0.01385283698896719,\n",
       " 0.03834080813674366,\n",
       " -0.017206350869055486]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the query\n",
    "query = \"How many ingredients will I need for this recipe?\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Componentes : Chains**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q&A : Indexing**\n",
    "\n",
    "- Cargar texto (documentos, base de conocimiento)\n",
    "- Trocear el texto para poder hacer llamadas a la API\n",
    "- Almacenar el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = \"What is the agent-based model?\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
